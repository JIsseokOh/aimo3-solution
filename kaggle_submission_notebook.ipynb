{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Mathematical Olympiad - Progress Prize 3\n",
    "## SC-TIR (Self-Consistency with Tool-Integrated Reasoning) Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages (fix version conflicts)\n!pip install -q --upgrade numpy==1.26.4\n!pip install -q transformers accelerate sympy"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "import traceback\n",
    "from collections import Counter\n",
    "from typing import Optional, List\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "IS_SUBMISSION = bool(os.getenv('KAGGLE_IS_COMPETITION_RERUN'))\n",
    "print(f\"Is submission: {IS_SUBMISSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nclass Config:\n    model_id = \"/kaggle/input/math_numina_7b_tir/pytorch/default/1\"  # NuminaMath-7B-TIR\n    num_samples = 32  # Number of samples for self-consistency\n    temperature = 0.7\n    max_new_tokens = 2048\n    top_p = 0.95\n    code_timeout = 10  # seconds"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a world-class mathematician solving olympiad-level math problems.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "1. Think step by step carefully\n",
    "2. Write Python code to verify calculations when needed\n",
    "3. Put your code inside ```python and ``` tags\n",
    "4. Your final answer must be a single non-negative integer\n",
    "5. Put your FINAL answer inside \\\\boxed{} at the very end\n",
    "\n",
    "Example:\n",
    "Let me solve this step by step...\n",
    "\n",
    "```python\n",
    "result = 2 + 2\n",
    "print(result)\n",
    "```\n",
    "\n",
    "The calculation gives 4.\n",
    "Therefore, the answer is \\\\boxed{4}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_blocks(text: str) -> List[str]:\n",
    "    \"\"\"Extract Python code blocks from text\"\"\"\n",
    "    pattern = r'```python\\s*(.*?)\\s*```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return matches\n",
    "\n",
    "def execute_code_safely(code: str) -> tuple:\n",
    "    \"\"\"Execute code safely and return result\"\"\"\n",
    "    import math\n",
    "    import cmath\n",
    "    import fractions\n",
    "    import itertools\n",
    "    import functools\n",
    "    from decimal import Decimal\n",
    "    \n",
    "    try:\n",
    "        import sympy\n",
    "        import numpy as np\n",
    "    except:\n",
    "        sympy = None\n",
    "        np = None\n",
    "    \n",
    "    safe_globals = {\n",
    "        \"__builtins__\": {\n",
    "            \"abs\": abs, \"all\": all, \"any\": any, \"bin\": bin,\n",
    "            \"bool\": bool, \"dict\": dict, \"divmod\": divmod,\n",
    "            \"enumerate\": enumerate, \"filter\": filter, \"float\": float,\n",
    "            \"int\": int, \"len\": len, \"list\": list, \"map\": map,\n",
    "            \"max\": max, \"min\": min, \"pow\": pow, \"print\": print,\n",
    "            \"range\": range, \"round\": round, \"set\": set, \"sorted\": sorted,\n",
    "            \"str\": str, \"sum\": sum, \"tuple\": tuple, \"zip\": zip,\n",
    "            \"True\": True, \"False\": False, \"None\": None,\n",
    "        },\n",
    "        \"math\": math,\n",
    "        \"cmath\": cmath,\n",
    "        \"fractions\": fractions,\n",
    "        \"Fraction\": fractions.Fraction,\n",
    "        \"itertools\": itertools,\n",
    "        \"functools\": functools,\n",
    "        \"Decimal\": Decimal,\n",
    "    }\n",
    "    \n",
    "    if sympy:\n",
    "        safe_globals[\"sympy\"] = sympy\n",
    "    if np is not None:\n",
    "        safe_globals[\"np\"] = np\n",
    "        safe_globals[\"numpy\"] = np\n",
    "    \n",
    "    stdout_capture = StringIO()\n",
    "    \n",
    "    try:\n",
    "        with redirect_stdout(stdout_capture):\n",
    "            exec(code, safe_globals)\n",
    "        return True, stdout_capture.getvalue()\n",
    "    except Exception as e:\n",
    "        return False, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(text: str) -> Optional[int]:\n",
    "    \"\"\"Extract final answer from text\"\"\"\n",
    "    # Look for \\boxed{...} pattern first\n",
    "    boxed_pattern = r'\\\\boxed\\{([^}]+)\\}'\n",
    "    matches = re.findall(boxed_pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        answer_str = matches[-1].strip()\n",
    "        numbers = re.findall(r'-?\\d+', answer_str)\n",
    "        if numbers:\n",
    "            try:\n",
    "                return int(numbers[-1]) % 100000\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Look for \"answer is X\" patterns\n",
    "    patterns = [\n",
    "        r'answer\\s*(?:is|=|:)\\s*(\\d+)',\n",
    "        r'remainder\\s*(?:is|=|:)\\s*(\\d+)',\n",
    "        r'final\\s*answer\\s*(?:is|=|:)?\\s*(\\d+)',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text.lower())\n",
    "        if matches:\n",
    "            try:\n",
    "                return int(matches[-1]) % 100000\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Last resort: find last number\n",
    "    numbers = re.findall(r'\\b(\\d+)\\b', text[-500:])\n",
    "    if numbers:\n",
    "        try:\n",
    "            return int(numbers[-1]) % 100000\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load model using transformers\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nprint(\"Loading model...\")\n\ntokenizer = AutoTokenizer.from_pretrained(\n    Config.model_id, \n    trust_remote_code=True\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    Config.model_id,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nprint(f\"Model loaded: {Config.model_id}\")\nprint(f\"Device: {model.device}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def solve_problem(problem: str) -> int:\n    \"\"\"Solve a math problem using SC-TIR\"\"\"\n    prompt = f\"{SYSTEM_PROMPT}\\n\\nProblem: {problem}\\n\\nSolution:\"\n    \n    answers = []\n    \n    for i in range(Config.num_samples):\n        try:\n            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n            \n            with torch.no_grad():\n                outputs = model.generate(\n                    **inputs,\n                    max_new_tokens=Config.max_new_tokens,\n                    temperature=Config.temperature,\n                    top_p=Config.top_p,\n                    do_sample=True,\n                    pad_token_id=tokenizer.eos_token_id,\n                )\n            \n            response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n            \n            # Execute code blocks\n            code_blocks = extract_code_blocks(response)\n            for code in code_blocks:\n                success, result = execute_code_safely(code)\n                if success and result.strip():\n                    try:\n                        num = int(result.strip().split()[-1])\n                        response += f\"\\nCode output: {num}\"\n                    except:\n                        pass\n            \n            # Extract answer\n            answer = extract_answer(response)\n            if answer is not None:\n                answers.append(answer)\n                \n        except Exception as e:\n            print(f\"  Sample {i+1} error: {e}\")\n            continue\n    \n    # Majority voting\n    if answers:\n        counter = Counter(answers)\n        most_common = counter.most_common(1)[0]\n        print(f\"  Votes: {dict(counter.most_common(5))}\")\n        return most_common[0]\n    \n    return 0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_path = '/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv'\n",
    "test_df = pl.read_csv(test_path)\n",
    "print(f\"Loaded {len(test_df)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve all problems\n",
    "results = []\n",
    "\n",
    "for row in test_df.iter_rows(named=True):\n",
    "    problem_id = row['id']\n",
    "    problem = row['problem']\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Solving: {problem_id}\")\n",
    "    print(f\"Problem: {problem[:100]}...\")\n",
    "    \n",
    "    start = time.time()\n",
    "    answer = solve_problem(problem)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Answer: {answer} (took {elapsed:.1f}s)\")\n",
    "    \n",
    "    results.append({'id': problem_id, 'answer': answer})\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Completed all {len(results)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission_df = pl.DataFrame(results)\n",
    "submission_df.write_csv('/kaggle/working/submission.csv')\n",
    "print(\"Submission saved!\")\n",
    "print(submission_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}